{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"9c3fe67966fadd35898ea10876c2d25074ac0ea19f3e5bbc4643b728a1d5eddb"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install gdown","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:15:59.497127Z","iopub.execute_input":"2022-10-10T08:15:59.498192Z","iopub.status.idle":"2022-10-10T08:16:23.628222Z","shell.execute_reply.started":"2022-10-10T08:15:59.498085Z","shell.execute_reply":"2022-10-10T08:16:23.627127Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.5.1.tar.gz (14 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.11.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.7.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.64.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.15.0)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.28.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.6.15.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.3)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\nBuilding wheels for collected packages: gdown\n  Building wheel for gdown (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gdown: filename=gdown-4.5.1-py3-none-any.whl size=14933 sha256=c5d87b827dcc89f40504b5eacfa78d0973529ae42a05cd3df6d14e2696cc9f44\n  Stored in directory: /root/.cache/pip/wheels/3d/ec/b0/a96d1d126183f98570a785e6bf8789fca559853a9260e928e1\nSuccessfully built gdown\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import gdown\nurl = 'https://drive.google.com/uc?id=166yBhZLRkYDY-xqw4m0P4Ioc4GyjUVdI'\noutput = 'modelka.zip'\ngdown.download(url, output, quiet=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:17:08.335006Z","iopub.execute_input":"2022-10-10T08:17:08.335594Z","iopub.status.idle":"2022-10-10T08:17:15.628217Z","shell.execute_reply.started":"2022-10-10T08:17:08.335534Z","shell.execute_reply":"2022-10-10T08:17:15.627134Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?id=166yBhZLRkYDY-xqw4m0P4Ioc4GyjUVdI\nTo: /kaggle/working/modelka.zip\n100%|██████████| 521M/521M [00:05<00:00, 93.0MB/s] \n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'modelka.zip'"},"metadata":{}}]},{"cell_type":"code","source":"!unzip modelka.zip","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:17:17.027903Z","iopub.execute_input":"2022-10-10T08:17:17.028825Z","iopub.status.idle":"2022-10-10T08:17:29.550033Z","shell.execute_reply.started":"2022-10-10T08:17:17.028787Z","shell.execute_reply":"2022-10-10T08:17:29.548877Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Archive:  modelka.zip\n  inflating: config.json             \n  inflating: pytorch_model.bin       \n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler\n\nimport transformers\nfrom transformers import XLMRobertaModel, XLMRobertaTokenizer, XLMRobertaConfig\nfrom transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n\nimport re","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:17:42.711516Z","iopub.execute_input":"2022-10-10T08:17:42.711928Z","iopub.status.idle":"2022-10-10T08:17:50.035708Z","shell.execute_reply.started":"2022-10-10T08:17:42.711889Z","shell.execute_reply":"2022-10-10T08:17:50.034656Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 224\npath = \"./\"\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:18:42.425008Z","iopub.execute_input":"2022-10-10T08:18:42.426064Z","iopub.status.idle":"2022-10-10T08:18:42.431530Z","shell.execute_reply.started":"2022-10-10T08:18:42.426014Z","shell.execute_reply":"2022-10-10T08:18:42.430401Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def onehot(size, target):\n    vec = torch.zeros(size, dtype=torch.float32)\n    vec[target] = 1.\n    return vec\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, df):\n        self.texts = df['text'].values\n        self.labels = df['lang'].values\n        self.tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n\n    def get_tokens(self, text):\n        encoded = self.tokenizer.encode_plus(text, add_special_tokens=True,max_length=MAX_LEN,pad_to_max_length=True)\n        return encoded['input_ids'], encoded['attention_mask']\n\n    def __len__(self):\n        return self.labels.shape[0]\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = torch.tensor(int(self.labels[idx])).long()\n        target = onehot(2, label)\n        tokens, attention_mask = self.get_tokens(text)\n        tokens, attention_mask = torch.tensor(tokens), torch.tensor(attention_mask)\n\n        return target, tokens, attention_mask","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:18:45.459237Z","iopub.execute_input":"2022-10-10T08:18:45.459984Z","iopub.status.idle":"2022-10-10T08:18:45.468837Z","shell.execute_reply.started":"2022-10-10T08:18:45.459949Z","shell.execute_reply":"2022-10-10T08:18:45.467668Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class CustomRoberta(nn.Module):\n    def __init__(self):\n        super(CustomRoberta, self).__init__()\n        self.num_labels = 2\n        self.roberta = transformers.XLMRobertaModel.from_pretrained(path)\n        self.dropout = nn.Dropout(p=0.3)\n        self.linear = nn.Linear(\n            in_features=self.roberta.pooler.dense.out_features*2,\n            out_features=2,\n        )\n        \n\n    def forward(self,\n                input_ids=None,\n                attention_mask=None,\n                position_ids=None,\n                head_mask=None,\n                inputs_embeds=None):\n\n        o1, o2 = self.roberta(input_ids,\n                               attention_mask=attention_mask,\n                               position_ids=position_ids,\n                               head_mask=head_mask,\n                               inputs_embeds=inputs_embeds)\n        apool = torch.mean(o1, 1)\n        mpool, _ = torch.max(o1, 1)\n        x = torch.cat((apool, mpool), 1)\n        x = self.dropout(x)\n        return self.linear(x)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:18:49.154778Z","iopub.execute_input":"2022-10-10T08:18:49.155179Z","iopub.status.idle":"2022-10-10T08:18:49.164704Z","shell.execute_reply.started":"2022-10-10T08:18:49.155144Z","shell.execute_reply":"2022-10-10T08:18:49.163742Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = CustomRoberta()","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:18:51.191768Z","iopub.execute_input":"2022-10-10T08:18:51.192411Z","iopub.status.idle":"2022-10-10T08:18:54.633395Z","shell.execute_reply.started":"2022-10-10T08:18:51.192366Z","shell.execute_reply":"2022-10-10T08:18:54.632476Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at ./ were not used when initializing XLMRobertaModel: ['linear.bias', 'linear.weight']\n- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"./pytorch_model.bin\", map_location=device))","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:19:07.370757Z","iopub.execute_input":"2022-10-10T08:19:07.371436Z","iopub.status.idle":"2022-10-10T08:19:13.155516Z","shell.execute_reply.started":"2022-10-10T08:19:07.371398Z","shell.execute_reply":"2022-10-10T08:19:13.154279Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"def eval(testloader, model):\n    model.eval()\n    model = model.to(device)\n    total_loss = 0\n    correct_predictions = 0\n    total_predictions = 0\n    counter = 0\n    for step, (targets, inputs, attention_masks) in enumerate(testloader):\n        with torch.no_grad():\n            inputs = inputs.to(device)\n            attention_masks = attention_masks.to(device)\n            targets = targets.to(device)\n            output = model(inputs, attention_masks)\n            correct_predictions += (output.argmax(1) == targets.argmax(1)).type(torch.float).sum().item()\n            total_predictions += len(targets)\n    print(f\"Accuracy: {correct_predictions / total_predictions}\")","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:19:16.525674Z","iopub.execute_input":"2022-10-10T08:19:16.526050Z","iopub.status.idle":"2022-10-10T08:19:16.533736Z","shell.execute_reply.started":"2022-10-10T08:19:16.526017Z","shell.execute_reply":"2022-10-10T08:19:16.532482Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/datalang/test_data.csv\")\ndata['lang'] = np.where(data['lang'] == 'kz', 0, 1)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:19:19.613232Z","iopub.execute_input":"2022-10-10T08:19:19.614392Z","iopub.status.idle":"2022-10-10T08:19:19.660683Z","shell.execute_reply.started":"2022-10-10T08:19:19.614347Z","shell.execute_reply":"2022-10-10T08:19:19.659618Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"test_set = DatasetRetriever(data)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=16, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:19:23.011963Z","iopub.execute_input":"2022-10-10T08:19:23.012670Z","iopub.status.idle":"2022-10-10T08:19:26.694198Z","shell.execute_reply.started":"2022-10-10T08:19:23.012633Z","shell.execute_reply":"2022-10-10T08:19:26.693114Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15a70455734c469eabbdd0f124029adf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c03042a069144b92aa21021cde959a53"}},"metadata":{}}]},{"cell_type":"code","source":"eval(test_loader, model)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:19:29.955834Z","iopub.execute_input":"2022-10-10T08:19:29.956222Z","iopub.status.idle":"2022-10-10T08:20:24.308270Z","shell.execute_reply.started":"2022-10-10T08:19:29.956187Z","shell.execute_reply":"2022-10-10T08:20:24.307110Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.9994509265614276\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}