{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers==2.5.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/kaz-rus/data.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler\n\nimport time\nimport random\nfrom datetime import datetime\nfrom tqdm import tqdm\ntqdm.pandas()\n\nfrom transformers import XLMRobertaModel, XLMRobertaTokenizer, XLMRobertaConfig\nfrom transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n\nimport re\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test = train_test_split(data, train_size = 0.6)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LENGTH = 256","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def onehot(size, target):\n    vec = torch.zeros(size, dtype=torch.float32)\n    vec[target] = 1.\n    return vec\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, df):\n        self.texts = df['text'].values\n        self.labels = df['lang'].values\n        self.tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n\n    def get_tokens(self, text):\n        encoded = self.tokenizer.encode_plus(text, add_special_tokens=True,max_length=MAX_LENGTH,pad_to_max_length=True)\n        return encoded['input_ids'], encoded['attention_mask']\n\n    def __len__(self):\n        return self.labels.shape[0]\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        target = onehot(2, label)\n        tokens, attention_mask = self.get_tokens(text)\n        tokens, attention_mask = torch.tensor(tokens), torch.tensor(attention_mask)\n\n        return self.labels[idx], tokens, attention_mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NNModel(nn.Module):\n\n    def __init__(self, backbone):\n        super(NNModel, self).__init__()\n        self.backbone = backbone\n        self.dropout = nn.Dropout(0.3)\n        self.linear = nn.Linear(\n            in_features=self.backbone.pooler.dense.out_features*2,\n            out_features=2,\n        )\n\n    def forward(self, input_ids, attention_masks):\n        bs, seq_length = input_ids.shape\n        seq_x, _ = self.backbone(input_ids=input_ids, attention_mask=attention_masks)\n        apool = torch.mean(seq_x, 1)\n        mpool, _ = torch.max(seq_x, 1)\n        x = torch.cat((apool, mpool), 1)\n        x = self.dropout(x)\n        return self.linear(x)\n\n\nbackbone = XLMRobertaModel(XLMRobertaConfig.from_pretrained(\"xlm-roberta-base\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = NNModel(backbone)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = 1e-5\nepoch = 10\noptim = torch.optim.AdamW(model.parameters(), lr=lr)\ncriteria = nn.CrossEntropyLoss()\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n\ndef train_step(trainloader, model, e):\n    model.train()\n    model = model.to(device)\n    total_loss = 0\n    correct_predictions = 0\n    total_predictions = 0\n    counter = 0\n    for step, (targets, inputs, attention_masks) in enumerate(trainloader):\n        inputs = inputs.to(device)\n        attention_masks = attention_masks.to(device)\n        targets = targets.to(device)\n        optim.zero_grad()\n        output = model(inputs, attention_masks)\n        loss = criteria(output, targets)\n        correct_predictions += (output.argmax(1) == targets).type(torch.float).sum().item()\n        total_predictions += len(targets)\n        loss.backward()\n        optim.step()\n        if step % 50 == 0:\n            print(f\"step: {step} {correct_predictions / total_predictions}\")\n    print(\"Epoch = [{}], accuracy = [{}]\".format(e, correct_predictions / total_predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval(testloader, model):\n    model.eval()\n    model = model.to(device)\n    total_loss = 0\n    correct_predictions = 0\n    total_predictions = 0\n    counter = 0\n    for step, (targets, inputs, attention_masks) in enumerate(testloader):\n        with torch.no_grad():\n            inputs = inputs.to(device)\n            attention_masks = attention_masks.to(device)\n            targets = targets.to(device)\n            output = model(inputs, attention_masks)\n            loss = criteria(output, targets)\n            correct_predictions += (output.argmax(1) == targets).type(torch.float).sum().item()\n            total_predictions += len(targets)\n            if step % 50 == 0:\n                print(f\"step: {step} {correct_predictions / total_predictions}\")\n    print(f\"Validation: {correct_predictions / total_predictions}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = DatasetRetriever(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(train_set, batch_size=16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(epoch):\n    train_step(train_loader, model, i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink(r'model.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval(test_loader, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"model.pt\"\n\n# Save\ntorch.save(model.state_dict(), PATH)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}